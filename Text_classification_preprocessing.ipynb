{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katha9/github_actions/blob/master/Text_classification_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92577519",
      "metadata": {
        "id": "92577519"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25df8762",
      "metadata": {
        "id": "25df8762"
      },
      "outputs": [],
      "source": [
        "# importing the pickle files\n",
        "file_train = ('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/df_train.pkl')\n",
        "df_train = pickle.load(open(file_train, 'rb'))\n",
        "\n",
        "file_test = ('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/df_test.pkl')\n",
        "df_test = pickle.load(open(file_test, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e3bfec",
      "metadata": {
        "id": "f0e3bfec",
        "outputId": "2eb8cf89-4e6c-4a75-b7c3-fde4900c32a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>imageid</th>\n",
              "      <th>prdtypecode</th>\n",
              "      <th>imagesizes</th>\n",
              "      <th>mean_color_distr</th>\n",
              "      <th>mean_R</th>\n",
              "      <th>mean_G</th>\n",
              "      <th>mean_B</th>\n",
              "      <th>mean_color_non-white</th>\n",
              "      <th>mean_R_nw</th>\n",
              "      <th>mean_G_nw</th>\n",
              "      <th>mean_B_nw</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3804725264</td>\n",
              "      <td>1263597046</td>\n",
              "      <td>10</td>\n",
              "      <td>14010</td>\n",
              "      <td>(246.58462799999998, 246.77024799999998, 251.4...</td>\n",
              "      <td>246.584628</td>\n",
              "      <td>246.770248</td>\n",
              "      <td>251.474248</td>\n",
              "      <td>(162.62156126281596, 163.77763678814333, 210.5...</td>\n",
              "      <td>162.621561</td>\n",
              "      <td>163.777637</td>\n",
              "      <td>210.518932</td>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>de</td>\n",
              "      <td>olivia personalisiertes notizbuch   seiten  pu...</td>\n",
              "      <td>[olivia, personalisiertes, notizbuch, seiten, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>436067568</td>\n",
              "      <td>1008141237</td>\n",
              "      <td>2280</td>\n",
              "      <td>14854</td>\n",
              "      <td>(231.393308, 232.69754, 233.709468)</td>\n",
              "      <td>231.393308</td>\n",
              "      <td>232.697540</td>\n",
              "      <td>233.709468</td>\n",
              "      <td>(130.35282040427558, 137.05147634670337, 142.3...</td>\n",
              "      <td>130.352820</td>\n",
              "      <td>137.051476</td>\n",
              "      <td>142.391449</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>fr</td>\n",
              "      <td>journal des arts le n  du   lart et son marche...</td>\n",
              "      <td>[journal, arts, lart, marche, salon, dart, asi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>201115110</td>\n",
              "      <td>938777978</td>\n",
              "      <td>50</td>\n",
              "      <td>6898</td>\n",
              "      <td>(253.40757599999998, 251.50132, 249.347872)</td>\n",
              "      <td>253.407576</td>\n",
              "      <td>251.501320</td>\n",
              "      <td>249.347872</td>\n",
              "      <td>(229.89716781365803, 197.75952885124406, 163.9...</td>\n",
              "      <td>229.897168</td>\n",
              "      <td>197.759529</td>\n",
              "      <td>163.986765</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>fr</td>\n",
              "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
              "      <td>[grand, stylet, ergonomique, bleu, gamepad, ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50418756</td>\n",
              "      <td>457047496</td>\n",
              "      <td>1280</td>\n",
              "      <td>14404</td>\n",
              "      <td>(149.071656, 152.230752, 169.912284)</td>\n",
              "      <td>149.071656</td>\n",
              "      <td>152.230752</td>\n",
              "      <td>169.912284</td>\n",
              "      <td>(48.85420611728034, 54.84256380284434, 89.2727...</td>\n",
              "      <td>48.854206</td>\n",
              "      <td>54.842564</td>\n",
              "      <td>89.272753</td>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>de</td>\n",
              "      <td>peluche donald  europe  disneyland  marionnett...</td>\n",
              "      <td>[peluche, donald, europe, disneyland, marionne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>278535884</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>2705</td>\n",
              "      <td>20435</td>\n",
              "      <td>(238.19055999999998, 234.07349599999998, 225.4...</td>\n",
              "      <td>238.190560</td>\n",
              "      <td>234.073496</td>\n",
              "      <td>225.420976</td>\n",
              "      <td>(174.3060186166625, 154.5172772649309, 113.717...</td>\n",
              "      <td>174.306019</td>\n",
              "      <td>154.517277</td>\n",
              "      <td>113.717647</td>\n",
              "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
              "      <td>fr</td>\n",
              "      <td>la guerre des tuques luc a des ideacutees de g...</td>\n",
              "      <td>[guerre, tuques, luc, ideacutees, grandeur, ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         designation  \\\n",
              "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
              "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
              "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
              "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
              "4                               La Guerre Des Tuques   \n",
              "\n",
              "                                         description   productid     imageid  \\\n",
              "0                                                NaN  3804725264  1263597046   \n",
              "1                                                NaN   436067568  1008141237   \n",
              "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
              "3                                                NaN    50418756   457047496   \n",
              "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
              "\n",
              "   prdtypecode  imagesizes                                   mean_color_distr  \\\n",
              "0           10       14010  (246.58462799999998, 246.77024799999998, 251.4...   \n",
              "1         2280       14854                (231.393308, 232.69754, 233.709468)   \n",
              "2           50        6898        (253.40757599999998, 251.50132, 249.347872)   \n",
              "3         1280       14404               (149.071656, 152.230752, 169.912284)   \n",
              "4         2705       20435  (238.19055999999998, 234.07349599999998, 225.4...   \n",
              "\n",
              "       mean_R      mean_G      mean_B  \\\n",
              "0  246.584628  246.770248  251.474248   \n",
              "1  231.393308  232.697540  233.709468   \n",
              "2  253.407576  251.501320  249.347872   \n",
              "3  149.071656  152.230752  169.912284   \n",
              "4  238.190560  234.073496  225.420976   \n",
              "\n",
              "                                mean_color_non-white   mean_R_nw   mean_G_nw  \\\n",
              "0  (162.62156126281596, 163.77763678814333, 210.5...  162.621561  163.777637   \n",
              "1  (130.35282040427558, 137.05147634670337, 142.3...  130.352820  137.051476   \n",
              "2  (229.89716781365803, 197.75952885124406, 163.9...  229.897168  197.759529   \n",
              "3  (48.85420611728034, 54.84256380284434, 89.2727...   48.854206   54.842564   \n",
              "4  (174.3060186166625, 154.5172772649309, 113.717...  174.306019  154.517277   \n",
              "\n",
              "    mean_B_nw                                               text language  \\\n",
              "0  210.518932  Olivia: Personalisiertes Notizbuch / 150 Seite...       de   \n",
              "1  142.391449  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...       fr   \n",
              "2  163.986765  Grand Stylet Ergonomique Bleu Gamepad Nintendo...       fr   \n",
              "3   89.272753  Peluche Donald - Europe - Disneyland 2000 (Mar...       de   \n",
              "4  113.717647  La Guerre Des Tuques Luc a des id&eacute;es de...       fr   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  olivia personalisiertes notizbuch   seiten  pu...   \n",
              "1  journal des arts le n  du   lart et son marche...   \n",
              "2  grand stylet ergonomique bleu gamepad nintendo...   \n",
              "3  peluche donald  europe  disneyland  marionnett...   \n",
              "4  la guerre des tuques luc a des ideacutees de g...   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [olivia, personalisiertes, notizbuch, seiten, ...  \n",
              "1  [journal, arts, lart, marche, salon, dart, asi...  \n",
              "2  [grand, stylet, ergonomique, bleu, gamepad, ni...  \n",
              "3  [peluche, donald, europe, disneyland, marionne...  \n",
              "4  [guerre, tuques, luc, ideacutees, grandeur, ve...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1362f0",
      "metadata": {
        "id": "8c1362f0",
        "outputId": "2bd80c49-b703-4ca3-d803-ae44fa7ded94"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>imageid</th>\n",
              "      <th>imagesizes</th>\n",
              "      <th>mean_color_distr</th>\n",
              "      <th>mean_R</th>\n",
              "      <th>mean_G</th>\n",
              "      <th>mean_B</th>\n",
              "      <th>mean_color_non-white</th>\n",
              "      <th>mean_R_nw</th>\n",
              "      <th>mean_G_nw</th>\n",
              "      <th>mean_B_nw</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84916</td>\n",
              "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>516376098</td>\n",
              "      <td>1019294171</td>\n",
              "      <td>15398</td>\n",
              "      <td>(224.22046, 231.54565599999998, 238.2208839999...</td>\n",
              "      <td>224.220460</td>\n",
              "      <td>231.545656</td>\n",
              "      <td>238.220884</td>\n",
              "      <td>(142.03779977929406, 166.04344176937784, 189.8...</td>\n",
              "      <td>142.037800</td>\n",
              "      <td>166.043442</td>\n",
              "      <td>189.859354</td>\n",
              "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
              "      <td>en</td>\n",
              "      <td>folkmanis puppets    marionnette et thtre  min...</td>\n",
              "      <td>[folkmanis, puppets, marionnette, thtre, mini,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84917</td>\n",
              "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>133389013</td>\n",
              "      <td>1274228667</td>\n",
              "      <td>42379</td>\n",
              "      <td>(137.94125599999998, 141.291904, 160.74312)</td>\n",
              "      <td>137.941256</td>\n",
              "      <td>141.291904</td>\n",
              "      <td>160.743120</td>\n",
              "      <td>(93.70194947679484, 98.33163709739665, 125.091...</td>\n",
              "      <td>93.701949</td>\n",
              "      <td>98.331637</td>\n",
              "      <td>125.091200</td>\n",
              "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
              "      <td>en</td>\n",
              "      <td>porte flamme gaxix  flamebringer gaxix    u  t...</td>\n",
              "      <td>[porte, flamme, gaxix, flamebringer, gaxix, u,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84918</td>\n",
              "      <td>Pompe de filtration Speck Badu 95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4128438366</td>\n",
              "      <td>1295960357</td>\n",
              "      <td>17383</td>\n",
              "      <td>(187.79458, 187.626484, 186.746712)</td>\n",
              "      <td>187.794580</td>\n",
              "      <td>187.626484</td>\n",
              "      <td>186.746712</td>\n",
              "      <td>(73.11408770979968, 72.63328641039523, 70.2774...</td>\n",
              "      <td>73.114088</td>\n",
              "      <td>72.633286</td>\n",
              "      <td>70.277466</td>\n",
              "      <td>Pompe de filtration Speck Badu 95</td>\n",
              "      <td>ro</td>\n",
              "      <td>pompe de filtration speck badu</td>\n",
              "      <td>[pompe, filtration, speck, badu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84919</td>\n",
              "      <td>Robot de piscine électrique</td>\n",
              "      <td>&lt;p&gt;Ce robot de piscine d&amp;#39;un design innovan...</td>\n",
              "      <td>3929899732</td>\n",
              "      <td>1265224052</td>\n",
              "      <td>27172</td>\n",
              "      <td>(194.490984, 179.90823999999998, 189.180751999...</td>\n",
              "      <td>194.490984</td>\n",
              "      <td>179.908240</td>\n",
              "      <td>189.180752</td>\n",
              "      <td>(134.00024836957394, 104.7708350024837, 123.38...</td>\n",
              "      <td>134.000248</td>\n",
              "      <td>104.770835</td>\n",
              "      <td>123.388186</td>\n",
              "      <td>Robot de piscine électrique &lt;p&gt;Ce robot de pis...</td>\n",
              "      <td>fr</td>\n",
              "      <td>robot de piscine lectrique pce robot de piscin...</td>\n",
              "      <td>[robot, piscine, lectrique, pce, robot, piscin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84920</td>\n",
              "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>152993898</td>\n",
              "      <td>940543690</td>\n",
              "      <td>8056</td>\n",
              "      <td>(243.264692, 242.88031999999998, 242.55372)</td>\n",
              "      <td>243.264692</td>\n",
              "      <td>242.880320</td>\n",
              "      <td>242.553720</td>\n",
              "      <td>(183.09926209212816, 180.7431296119242, 178.76...</td>\n",
              "      <td>183.099262</td>\n",
              "      <td>180.743130</td>\n",
              "      <td>178.767351</td>\n",
              "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
              "      <td>fr</td>\n",
              "      <td>hsm destructeur securio c coupe croise  x  mm</td>\n",
              "      <td>[hsm, destructeur, securio, coupe, croise]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                        designation  \\\n",
              "0       84916  Folkmanis Puppets - 2732 - Marionnette Et Théâ...   \n",
              "1       84917  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...   \n",
              "2       84918                  Pompe de filtration Speck Badu 95   \n",
              "3       84919                        Robot de piscine électrique   \n",
              "4       84920  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...   \n",
              "\n",
              "                                         description   productid     imageid  \\\n",
              "0                                                NaN   516376098  1019294171   \n",
              "1                                                NaN   133389013  1274228667   \n",
              "2                                                NaN  4128438366  1295960357   \n",
              "3  <p>Ce robot de piscine d&#39;un design innovan...  3929899732  1265224052   \n",
              "4                                                NaN   152993898   940543690   \n",
              "\n",
              "   imagesizes                                   mean_color_distr      mean_R  \\\n",
              "0       15398  (224.22046, 231.54565599999998, 238.2208839999...  224.220460   \n",
              "1       42379        (137.94125599999998, 141.291904, 160.74312)  137.941256   \n",
              "2       17383                (187.79458, 187.626484, 186.746712)  187.794580   \n",
              "3       27172  (194.490984, 179.90823999999998, 189.180751999...  194.490984   \n",
              "4        8056        (243.264692, 242.88031999999998, 242.55372)  243.264692   \n",
              "\n",
              "       mean_G      mean_B                               mean_color_non-white  \\\n",
              "0  231.545656  238.220884  (142.03779977929406, 166.04344176937784, 189.8...   \n",
              "1  141.291904  160.743120  (93.70194947679484, 98.33163709739665, 125.091...   \n",
              "2  187.626484  186.746712  (73.11408770979968, 72.63328641039523, 70.2774...   \n",
              "3  179.908240  189.180752  (134.00024836957394, 104.7708350024837, 123.38...   \n",
              "4  242.880320  242.553720  (183.09926209212816, 180.7431296119242, 178.76...   \n",
              "\n",
              "    mean_R_nw   mean_G_nw   mean_B_nw  \\\n",
              "0  142.037800  166.043442  189.859354   \n",
              "1   93.701949   98.331637  125.091200   \n",
              "2   73.114088   72.633286   70.277466   \n",
              "3  134.000248  104.770835  123.388186   \n",
              "4  183.099262  180.743130  178.767351   \n",
              "\n",
              "                                                text language  \\\n",
              "0  Folkmanis Puppets - 2732 - Marionnette Et Théâ...       en   \n",
              "1  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...       en   \n",
              "2                 Pompe de filtration Speck Badu 95        ro   \n",
              "3  Robot de piscine électrique <p>Ce robot de pis...       fr   \n",
              "4  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...       fr   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  folkmanis puppets    marionnette et thtre  min...   \n",
              "1  porte flamme gaxix  flamebringer gaxix    u  t...   \n",
              "2                   pompe de filtration speck badu     \n",
              "3  robot de piscine lectrique pce robot de piscin...   \n",
              "4     hsm destructeur securio c coupe croise  x  mm    \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [folkmanis, puppets, marionnette, thtre, mini,...  \n",
              "1  [porte, flamme, gaxix, flamebringer, gaxix, u,...  \n",
              "2                   [pompe, filtration, speck, badu]  \n",
              "3  [robot, piscine, lectrique, pce, robot, piscin...  \n",
              "4         [hsm, destructeur, securio, coupe, croise]  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ef4d67",
      "metadata": {
        "id": "a2ef4d67"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6fe966f",
      "metadata": {
        "id": "a6fe966f",
        "outputId": "1e8e1848-eda1-4d1a-cf53-9e4d4698806c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13812 entries, 0 to 13811\n",
            "Data columns (total 17 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   designation           13812 non-null  object \n",
            " 1   description           8926 non-null   object \n",
            " 2   productid             13812 non-null  int64  \n",
            " 3   imageid               13812 non-null  int64  \n",
            " 4   imagesizes            13812 non-null  int64  \n",
            " 5   mean_color_distr      13812 non-null  object \n",
            " 6   mean_R                13812 non-null  float64\n",
            " 7   mean_G                13812 non-null  float64\n",
            " 8   mean_B                13812 non-null  float64\n",
            " 9   mean_color_non-white  13812 non-null  object \n",
            " 10  mean_R_nw             13812 non-null  float64\n",
            " 11  mean_G_nw             13812 non-null  float64\n",
            " 12  mean_B_nw             13812 non-null  float64\n",
            " 13  text                  13812 non-null  object \n",
            " 14  language              13812 non-null  object \n",
            " 15  cleaned_text          13812 non-null  object \n",
            " 16  tokenized_text        13812 non-null  object \n",
            "dtypes: float64(6), int64(3), object(8)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f894d94",
      "metadata": {
        "id": "2f894d94",
        "outputId": "f9c6ae7d-9c8a-4051-d313-8c2657f08eda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fr</td>\n",
              "      <td>76.519148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en</td>\n",
              "      <td>14.696877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>3.263225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>nl</td>\n",
              "      <td>1.247115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca</td>\n",
              "      <td>0.936219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>it</td>\n",
              "      <td>0.728956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ro</td>\n",
              "      <td>0.420415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>es</td>\n",
              "      <td>0.386264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>pt</td>\n",
              "      <td>0.350935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>id</td>\n",
              "      <td>0.241415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>no</td>\n",
              "      <td>0.183711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>af</td>\n",
              "      <td>0.150737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>tl</td>\n",
              "      <td>0.141316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>da</td>\n",
              "      <td>0.107165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>et</td>\n",
              "      <td>0.081257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>sw</td>\n",
              "      <td>0.073013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>sv</td>\n",
              "      <td>0.060059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>so</td>\n",
              "      <td>0.052994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>hr</td>\n",
              "      <td>0.049461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>cy</td>\n",
              "      <td>0.048283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>fi</td>\n",
              "      <td>0.045928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>sl</td>\n",
              "      <td>0.044750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>vi</td>\n",
              "      <td>0.043572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pl</td>\n",
              "      <td>0.043572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>tr</td>\n",
              "      <td>0.029441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>hu</td>\n",
              "      <td>0.012954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>lt</td>\n",
              "      <td>0.011776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>sk</td>\n",
              "      <td>0.009421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>lv</td>\n",
              "      <td>0.007066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>sq</td>\n",
              "      <td>0.007066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>cs</td>\n",
              "      <td>0.005888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Language  Percentage\n",
              "1        fr   76.519148\n",
              "3        en   14.696877\n",
              "0        de    3.263225\n",
              "6        nl    1.247115\n",
              "4        ca    0.936219\n",
              "9        it    0.728956\n",
              "5        ro    0.420415\n",
              "7        es    0.386264\n",
              "8        pt    0.350935\n",
              "11       id    0.241415\n",
              "10       no    0.183711\n",
              "13       af    0.150737\n",
              "17       tl    0.141316\n",
              "16       da    0.107165\n",
              "14       et    0.081257\n",
              "21       sw    0.073013\n",
              "18       sv    0.060059\n",
              "12       so    0.052994\n",
              "23       hr    0.049461\n",
              "19       cy    0.048283\n",
              "15       fi    0.045928\n",
              "25       sl    0.044750\n",
              "20       vi    0.043572\n",
              "2        pl    0.043572\n",
              "28       tr    0.029441\n",
              "24       hu    0.012954\n",
              "22       lt    0.011776\n",
              "26       sk    0.009421\n",
              "27       lv    0.007066\n",
              "30       sq    0.007066\n",
              "29       cs    0.005888"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# I am considering to use lemmatization. As this only makes sense if I know the languages, I am thinking to drop\n",
        "# languages that are only contained to a limited extent.\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Count occurrences of each language\n",
        "language_counts = Counter(df_train['language'])\n",
        "\n",
        "# Calculate the percentage of each language\n",
        "total = sum(language_counts.values())\n",
        "language_percentages_train = {lang: count / total * 100 for lang, count in language_counts.items()}\n",
        "\n",
        "# Convert to DataFrame\n",
        "language_percentages_df_train = pd.DataFrame(list(language_percentages_train.items()), columns=['Language', 'Percentage'])\n",
        "\n",
        "# Sort the DataFrame by percentage\n",
        "language_percentages_df_train = language_percentages_df_train.sort_values(by='Percentage', ascending=False)\n",
        "\n",
        "# Display the result\n",
        "language_percentages_df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf35e4a",
      "metadata": {
        "id": "7bf35e4a",
        "outputId": "5f19de3c-c7f5-4b1a-8e23-96617fd14d0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fr</td>\n",
              "      <td>76.129453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>14.784246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>de</td>\n",
              "      <td>3.344917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>nl</td>\n",
              "      <td>1.151173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ca</td>\n",
              "      <td>1.035332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>it</td>\n",
              "      <td>0.803649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>es</td>\n",
              "      <td>0.514046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ro</td>\n",
              "      <td>0.499566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pt</td>\n",
              "      <td>0.325804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>id</td>\n",
              "      <td>0.282363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>af</td>\n",
              "      <td>0.173762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>no</td>\n",
              "      <td>0.152042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tl</td>\n",
              "      <td>0.144802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>sw</td>\n",
              "      <td>0.094121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>sv</td>\n",
              "      <td>0.086881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sl</td>\n",
              "      <td>0.079641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>et</td>\n",
              "      <td>0.072401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>fi</td>\n",
              "      <td>0.065161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>da</td>\n",
              "      <td>0.050681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>cy</td>\n",
              "      <td>0.043440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>sk</td>\n",
              "      <td>0.028960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>so</td>\n",
              "      <td>0.028960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>hu</td>\n",
              "      <td>0.028960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hr</td>\n",
              "      <td>0.021720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>cs</td>\n",
              "      <td>0.014480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>vi</td>\n",
              "      <td>0.014480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>pl</td>\n",
              "      <td>0.007240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>lt</td>\n",
              "      <td>0.007240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>lv</td>\n",
              "      <td>0.007240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>tr</td>\n",
              "      <td>0.007240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Language  Percentage\n",
              "2        fr   76.129453\n",
              "0        en   14.784246\n",
              "6        de    3.344917\n",
              "10       nl    1.151173\n",
              "11       ca    1.035332\n",
              "7        it    0.803649\n",
              "5        es    0.514046\n",
              "1        ro    0.499566\n",
              "4        pt    0.325804\n",
              "8        id    0.282363\n",
              "9        af    0.173762\n",
              "16       no    0.152042\n",
              "13       tl    0.144802\n",
              "19       sw    0.094121\n",
              "12       sv    0.086881\n",
              "14       sl    0.079641\n",
              "3        et    0.072401\n",
              "22       fi    0.065161\n",
              "17       da    0.050681\n",
              "23       cy    0.043440\n",
              "25       sk    0.028960\n",
              "20       so    0.028960\n",
              "24       hu    0.028960\n",
              "15       hr    0.021720\n",
              "18       cs    0.014480\n",
              "26       vi    0.014480\n",
              "21       pl    0.007240\n",
              "27       lt    0.007240\n",
              "28       lv    0.007240\n",
              "29       tr    0.007240"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# I repeat this process for the test data set\n",
        "\n",
        "# Count occurrences of each language\n",
        "language_counts = Counter(df_test['language'])\n",
        "\n",
        "# Calculate the percentage of each language\n",
        "total = sum(language_counts.values())\n",
        "language_percentages_test = {lang: count / total * 100 for lang, count in language_counts.items()}\n",
        "\n",
        "# Convert to DataFrame\n",
        "language_percentages_df_test = pd.DataFrame(list(language_percentages_test.items()), columns=['Language', 'Percentage'])\n",
        "\n",
        "# Sort the DataFrame by percentage\n",
        "language_percentages_df_test = language_percentages_df_test.sort_values(by='Percentage', ascending=False)\n",
        "\n",
        "# Display the result\n",
        "language_percentages_df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17d8cab",
      "metadata": {
        "id": "a17d8cab",
        "outputId": "dbd71110-75bd-4b5c-f099-8db743d772ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "languages df_train: ['fr' 'en']\n",
            "languages df_test: ['en' 'fr']\n"
          ]
        }
      ],
      "source": [
        "# As both data sets consist of 90% French and English, I will drop the other languages\n",
        "\n",
        "df_train = df_train.loc[(df_train['language'] == 'fr') | (df_train['language'] == 'en')]\n",
        "df_test = df_test.loc[(df_test['language'] == 'fr') | (df_test['language'] == 'en')]\n",
        "\n",
        "print(\"languages df_train:\", df_train['language'].unique())\n",
        "print(\"languages df_test:\", df_test['language'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc9b09d",
      "metadata": {
        "id": "9cc9b09d",
        "outputId": "06b45d05-32a6-4573-ec23-0444b80e311e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_train shape: (77457, 18)\n",
            "df_test shape: (12557, 17)\n"
          ]
        }
      ],
      "source": [
        "# I check the shape of the data frames to see if there is still aroung 15% test data and 85% train data\n",
        "print(\"df_train shape:\", df_train.shape)\n",
        "print(\"df_test shape:\", df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d1478f",
      "metadata": {
        "id": "09d1478f",
        "outputId": "c128be6b-f4de-4c90-cefd-ae98e6abe17f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/katharinastock/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# The ratio from train to test data is still valid, therefore I will proceed with lemmatization\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "\n",
        "# Ensure the necessary NLTK resources are downloaded\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize lemmatizer and stemmer\n",
        "english_lemmatizer = WordNetLemmatizer()\n",
        "french_lemmatizer = SnowballStemmer('french')\n",
        "\n",
        "# Function to apply lemmatization to tokenized text\n",
        "def lemmatize_tokens(tokens, language):\n",
        "    if language == 'en':\n",
        "        return [english_lemmatizer.lemmatize(token) for token in tokens]\n",
        "    elif language == 'fr':\n",
        "        return [french_lemmatizer.stem(token) for token in tokens]\n",
        "\n",
        "# Apply lemmatization to the train dataframe\n",
        "df_train['lemmatized_text'] = df_train.apply(lambda row: lemmatize_tokens(row['tokenized_text'], row['language']), axis=1)\n",
        "\n",
        "# Apply lemmatization to the test dataframe\n",
        "df_test['lemmatized_text'] = df_test.apply(lambda row: lemmatize_tokens(row['tokenized_text'], row['language']), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0cac75",
      "metadata": {
        "id": "8c0cac75"
      },
      "outputs": [],
      "source": [
        "# I need to apply a conversion back from the lemmatized text to string to be able to apply TF-IDF\n",
        "\n",
        "# Process step 1: clean and tokenize the text\n",
        "# Step 2: apply lemmatization to the tokenized text\n",
        "# Step 3: convert the text back to string\n",
        "# Step 4: apply TF-IDF to the string\n",
        "\n",
        "# Convert tokenized text back to strings\n",
        "df_train['lemmatized_text_str'] = df_train['lemmatized_text'].apply(lambda x: ' '.join(x))\n",
        "df_test['lemmatized_text_str'] = df_test['lemmatized_text'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1c5536",
      "metadata": {
        "id": "3b1c5536",
        "outputId": "76d1a8d2-a8b0-484f-91b3-b1f5b4ac8738"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>imageid</th>\n",
              "      <th>prdtypecode</th>\n",
              "      <th>imagesizes</th>\n",
              "      <th>mean_color_distr</th>\n",
              "      <th>mean_R</th>\n",
              "      <th>mean_G</th>\n",
              "      <th>mean_B</th>\n",
              "      <th>mean_color_non-white</th>\n",
              "      <th>mean_R_nw</th>\n",
              "      <th>mean_G_nw</th>\n",
              "      <th>mean_B_nw</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_text_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>436067568</td>\n",
              "      <td>1008141237</td>\n",
              "      <td>2280</td>\n",
              "      <td>14854</td>\n",
              "      <td>(231.393308, 232.69754, 233.709468)</td>\n",
              "      <td>231.393308</td>\n",
              "      <td>232.697540</td>\n",
              "      <td>233.709468</td>\n",
              "      <td>(130.35282040427558, 137.05147634670337, 142.3...</td>\n",
              "      <td>130.352820</td>\n",
              "      <td>137.051476</td>\n",
              "      <td>142.391449</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>fr</td>\n",
              "      <td>journal des arts le n  du   lart et son marche...</td>\n",
              "      <td>[journal, arts, lart, marche, salon, dart, asi...</td>\n",
              "      <td>[journal, art, lart, march, salon, dart, asiat...</td>\n",
              "      <td>journal art lart march salon dart asiat paris ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>201115110</td>\n",
              "      <td>938777978</td>\n",
              "      <td>50</td>\n",
              "      <td>6898</td>\n",
              "      <td>(253.40757599999998, 251.50132, 249.347872)</td>\n",
              "      <td>253.407576</td>\n",
              "      <td>251.501320</td>\n",
              "      <td>249.347872</td>\n",
              "      <td>(229.89716781365803, 197.75952885124406, 163.9...</td>\n",
              "      <td>229.897168</td>\n",
              "      <td>197.759529</td>\n",
              "      <td>163.986765</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>fr</td>\n",
              "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
              "      <td>[grand, stylet, ergonomique, bleu, gamepad, ni...</td>\n",
              "      <td>[grand, stylet, ergonom, bleu, gamepad, ninten...</td>\n",
              "      <td>grand stylet ergonom bleu gamepad nintendo wii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>278535884</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>2705</td>\n",
              "      <td>20435</td>\n",
              "      <td>(238.19055999999998, 234.07349599999998, 225.4...</td>\n",
              "      <td>238.190560</td>\n",
              "      <td>234.073496</td>\n",
              "      <td>225.420976</td>\n",
              "      <td>(174.3060186166625, 154.5172772649309, 113.717...</td>\n",
              "      <td>174.306019</td>\n",
              "      <td>154.517277</td>\n",
              "      <td>113.717647</td>\n",
              "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
              "      <td>fr</td>\n",
              "      <td>la guerre des tuques luc a des ideacutees de g...</td>\n",
              "      <td>[guerre, tuques, luc, ideacutees, grandeur, ve...</td>\n",
              "      <td>[guerr, tuqu, luc, ideacute, grandeur, veut, o...</td>\n",
              "      <td>guerr tuqu luc ideacute grandeur veut organis ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5862738</td>\n",
              "      <td>393356830</td>\n",
              "      <td>2280</td>\n",
              "      <td>25910</td>\n",
              "      <td>(134.18705599999998, 186.39176, 247.070752)</td>\n",
              "      <td>134.187056</td>\n",
              "      <td>186.391760</td>\n",
              "      <td>247.070752</td>\n",
              "      <td>(57.805643452465034, 141.8980435089702, 241.05...</td>\n",
              "      <td>57.805643</td>\n",
              "      <td>141.898044</td>\n",
              "      <td>241.052352</td>\n",
              "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
              "      <td>fr</td>\n",
              "      <td>afrique contemporaine n  hiver   dossier japon...</td>\n",
              "      <td>[afrique, contemporaine, hiver, dossier, japon...</td>\n",
              "      <td>[afriqu, contemporain, hiv, dossi, japon, afriqu]</td>\n",
              "      <td>afriqu contemporain hiv dossi japon afriqu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
              "      <td>CONQUERANT CLASSIQUE Cahier 240 x 320 mm seyès...</td>\n",
              "      <td>344240059</td>\n",
              "      <td>999581347</td>\n",
              "      <td>2522</td>\n",
              "      <td>20324</td>\n",
              "      <td>(235.83785999999998, 233.31999199999998, 231.1...</td>\n",
              "      <td>235.837860</td>\n",
              "      <td>233.319992</td>\n",
              "      <td>231.170624</td>\n",
              "      <td>(215.85367509344152, 210.67668010697724, 206.3...</td>\n",
              "      <td>215.853675</td>\n",
              "      <td>210.676680</td>\n",
              "      <td>206.315207</td>\n",
              "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
              "      <td>fr</td>\n",
              "      <td>conqurant sept cahier couverture polypro  x  m...</td>\n",
              "      <td>[conqurant, sept, cahier, couverture, polypro,...</td>\n",
              "      <td>[conqur, sept, cahi, couvertur, polypro, pag, ...</td>\n",
              "      <td>conqur sept cahi couvertur polypro pag sey inc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         designation  \\\n",
              "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
              "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
              "4                               La Guerre Des Tuques   \n",
              "5  Afrique Contemporaine N° 212 Hiver 2004 - Doss...   \n",
              "7  Conquérant Sept Cahier Couverture Polypro 240 ...   \n",
              "\n",
              "                                         description  productid     imageid  \\\n",
              "1                                                NaN  436067568  1008141237   \n",
              "2  PILOT STYLE Touch Pen de marque Speedlink est ...  201115110   938777978   \n",
              "4  Luc a des id&eacute;es de grandeur. Il veut or...  278535884  1077757786   \n",
              "5                                                NaN    5862738   393356830   \n",
              "7  CONQUERANT CLASSIQUE Cahier 240 x 320 mm seyès...  344240059   999581347   \n",
              "\n",
              "   prdtypecode  imagesizes                                   mean_color_distr  \\\n",
              "1         2280       14854                (231.393308, 232.69754, 233.709468)   \n",
              "2           50        6898        (253.40757599999998, 251.50132, 249.347872)   \n",
              "4         2705       20435  (238.19055999999998, 234.07349599999998, 225.4...   \n",
              "5         2280       25910        (134.18705599999998, 186.39176, 247.070752)   \n",
              "7         2522       20324  (235.83785999999998, 233.31999199999998, 231.1...   \n",
              "\n",
              "       mean_R      mean_G      mean_B  \\\n",
              "1  231.393308  232.697540  233.709468   \n",
              "2  253.407576  251.501320  249.347872   \n",
              "4  238.190560  234.073496  225.420976   \n",
              "5  134.187056  186.391760  247.070752   \n",
              "7  235.837860  233.319992  231.170624   \n",
              "\n",
              "                                mean_color_non-white   mean_R_nw   mean_G_nw  \\\n",
              "1  (130.35282040427558, 137.05147634670337, 142.3...  130.352820  137.051476   \n",
              "2  (229.89716781365803, 197.75952885124406, 163.9...  229.897168  197.759529   \n",
              "4  (174.3060186166625, 154.5172772649309, 113.717...  174.306019  154.517277   \n",
              "5  (57.805643452465034, 141.8980435089702, 241.05...   57.805643  141.898044   \n",
              "7  (215.85367509344152, 210.67668010697724, 206.3...  215.853675  210.676680   \n",
              "\n",
              "    mean_B_nw                                               text language  \\\n",
              "1  142.391449  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...       fr   \n",
              "2  163.986765  Grand Stylet Ergonomique Bleu Gamepad Nintendo...       fr   \n",
              "4  113.717647  La Guerre Des Tuques Luc a des id&eacute;es de...       fr   \n",
              "5  241.052352  Afrique Contemporaine N° 212 Hiver 2004 - Doss...       fr   \n",
              "7  206.315207  Conquérant Sept Cahier Couverture Polypro 240 ...       fr   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "1  journal des arts le n  du   lart et son marche...   \n",
              "2  grand stylet ergonomique bleu gamepad nintendo...   \n",
              "4  la guerre des tuques luc a des ideacutees de g...   \n",
              "5  afrique contemporaine n  hiver   dossier japon...   \n",
              "7  conqurant sept cahier couverture polypro  x  m...   \n",
              "\n",
              "                                      tokenized_text  \\\n",
              "1  [journal, arts, lart, marche, salon, dart, asi...   \n",
              "2  [grand, stylet, ergonomique, bleu, gamepad, ni...   \n",
              "4  [guerre, tuques, luc, ideacutees, grandeur, ve...   \n",
              "5  [afrique, contemporaine, hiver, dossier, japon...   \n",
              "7  [conqurant, sept, cahier, couverture, polypro,...   \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "1  [journal, art, lart, march, salon, dart, asiat...   \n",
              "2  [grand, stylet, ergonom, bleu, gamepad, ninten...   \n",
              "4  [guerr, tuqu, luc, ideacute, grandeur, veut, o...   \n",
              "5  [afriqu, contemporain, hiv, dossi, japon, afriqu]   \n",
              "7  [conqur, sept, cahi, couvertur, polypro, pag, ...   \n",
              "\n",
              "                                 lemmatized_text_str  \n",
              "1  journal art lart march salon dart asiat paris ...  \n",
              "2  grand stylet ergonom bleu gamepad nintendo wii...  \n",
              "4  guerr tuqu luc ideacute grandeur veut organis ...  \n",
              "5         afriqu contemporain hiv dossi japon afriqu  \n",
              "7  conqur sept cahi couvertur polypro pag sey inc...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb0cbdd",
      "metadata": {
        "id": "9eb0cbdd",
        "outputId": "9f83b1a3-522d-4187-c246-7eb503b71d3c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>imageid</th>\n",
              "      <th>imagesizes</th>\n",
              "      <th>mean_color_distr</th>\n",
              "      <th>mean_R</th>\n",
              "      <th>mean_G</th>\n",
              "      <th>mean_B</th>\n",
              "      <th>mean_color_non-white</th>\n",
              "      <th>mean_R_nw</th>\n",
              "      <th>mean_G_nw</th>\n",
              "      <th>mean_B_nw</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>lemmatized_text_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>516376098</td>\n",
              "      <td>1019294171</td>\n",
              "      <td>15398</td>\n",
              "      <td>(224.22046, 231.54565599999998, 238.2208839999...</td>\n",
              "      <td>224.220460</td>\n",
              "      <td>231.545656</td>\n",
              "      <td>238.220884</td>\n",
              "      <td>(142.03779977929406, 166.04344176937784, 189.8...</td>\n",
              "      <td>142.037800</td>\n",
              "      <td>166.043442</td>\n",
              "      <td>189.859354</td>\n",
              "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
              "      <td>en</td>\n",
              "      <td>folkmanis puppets    marionnette et thtre  min...</td>\n",
              "      <td>[folkmanis, puppets, marionnette, thtre, mini,...</td>\n",
              "      <td>[folkmanis, puppet, marionnette, thtre, mini, ...</td>\n",
              "      <td>folkmanis puppet marionnette thtre mini turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>133389013</td>\n",
              "      <td>1274228667</td>\n",
              "      <td>42379</td>\n",
              "      <td>(137.94125599999998, 141.291904, 160.74312)</td>\n",
              "      <td>137.941256</td>\n",
              "      <td>141.291904</td>\n",
              "      <td>160.743120</td>\n",
              "      <td>(93.70194947679484, 98.33163709739665, 125.091...</td>\n",
              "      <td>93.701949</td>\n",
              "      <td>98.331637</td>\n",
              "      <td>125.091200</td>\n",
              "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
              "      <td>en</td>\n",
              "      <td>porte flamme gaxix  flamebringer gaxix    u  t...</td>\n",
              "      <td>[porte, flamme, gaxix, flamebringer, gaxix, u,...</td>\n",
              "      <td>[porte, flamme, gaxix, flamebringer, gaxix, u,...</td>\n",
              "      <td>porte flamme gaxix flamebringer gaxix u twilig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Robot de piscine électrique</td>\n",
              "      <td>&lt;p&gt;Ce robot de piscine d&amp;#39;un design innovan...</td>\n",
              "      <td>3929899732</td>\n",
              "      <td>1265224052</td>\n",
              "      <td>27172</td>\n",
              "      <td>(194.490984, 179.90823999999998, 189.180751999...</td>\n",
              "      <td>194.490984</td>\n",
              "      <td>179.908240</td>\n",
              "      <td>189.180752</td>\n",
              "      <td>(134.00024836957394, 104.7708350024837, 123.38...</td>\n",
              "      <td>134.000248</td>\n",
              "      <td>104.770835</td>\n",
              "      <td>123.388186</td>\n",
              "      <td>Robot de piscine électrique &lt;p&gt;Ce robot de pis...</td>\n",
              "      <td>fr</td>\n",
              "      <td>robot de piscine lectrique pce robot de piscin...</td>\n",
              "      <td>[robot, piscine, lectrique, pce, robot, piscin...</td>\n",
              "      <td>[robot, piscin, lectriqu, pce, robot, piscin, ...</td>\n",
              "      <td>robot piscin lectriqu pce robot piscin dun des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>152993898</td>\n",
              "      <td>940543690</td>\n",
              "      <td>8056</td>\n",
              "      <td>(243.264692, 242.88031999999998, 242.55372)</td>\n",
              "      <td>243.264692</td>\n",
              "      <td>242.880320</td>\n",
              "      <td>242.553720</td>\n",
              "      <td>(183.09926209212816, 180.7431296119242, 178.76...</td>\n",
              "      <td>183.099262</td>\n",
              "      <td>180.743130</td>\n",
              "      <td>178.767351</td>\n",
              "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
              "      <td>fr</td>\n",
              "      <td>hsm destructeur securio c coupe croise  x  mm</td>\n",
              "      <td>[hsm, destructeur, securio, coupe, croise]</td>\n",
              "      <td>[hsm, destructeur, securio, coup, crois]</td>\n",
              "      <td>hsm destructeur securio coup crois</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cadre Universal Pro Mont Accessoires Pour Dji ...</td>\n",
              "      <td>Cadre Universal Pro Mont Accessoires Pour DJI ...</td>\n",
              "      <td>4181949876</td>\n",
              "      <td>1310030687</td>\n",
              "      <td>19465</td>\n",
              "      <td>(222.62720399999998, 222.14148, 222.823244)</td>\n",
              "      <td>222.627204</td>\n",
              "      <td>222.141480</td>\n",
              "      <td>222.823244</td>\n",
              "      <td>(165.43741130033706, 164.00131940748625, 165.8...</td>\n",
              "      <td>165.437411</td>\n",
              "      <td>164.001319</td>\n",
              "      <td>165.840884</td>\n",
              "      <td>Cadre Universal Pro Mont Accessoires Pour Dji ...</td>\n",
              "      <td>fr</td>\n",
              "      <td>cadre universal pro mont accessoires pour dji ...</td>\n",
              "      <td>[cadre, universal, pro, mont, accessoires, dji...</td>\n",
              "      <td>[cadr, universal, pro, mont, accessoir, dji, o...</td>\n",
              "      <td>cadr universal pro mont accessoir dji osmo mob...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         designation  \\\n",
              "0  Folkmanis Puppets - 2732 - Marionnette Et Théâ...   \n",
              "1  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...   \n",
              "3                        Robot de piscine électrique   \n",
              "4  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...   \n",
              "5  Cadre Universal Pro Mont Accessoires Pour Dji ...   \n",
              "\n",
              "                                         description   productid     imageid  \\\n",
              "0                                                NaN   516376098  1019294171   \n",
              "1                                                NaN   133389013  1274228667   \n",
              "3  <p>Ce robot de piscine d&#39;un design innovan...  3929899732  1265224052   \n",
              "4                                                NaN   152993898   940543690   \n",
              "5  Cadre Universal Pro Mont Accessoires Pour DJI ...  4181949876  1310030687   \n",
              "\n",
              "   imagesizes                                   mean_color_distr      mean_R  \\\n",
              "0       15398  (224.22046, 231.54565599999998, 238.2208839999...  224.220460   \n",
              "1       42379        (137.94125599999998, 141.291904, 160.74312)  137.941256   \n",
              "3       27172  (194.490984, 179.90823999999998, 189.180751999...  194.490984   \n",
              "4        8056        (243.264692, 242.88031999999998, 242.55372)  243.264692   \n",
              "5       19465        (222.62720399999998, 222.14148, 222.823244)  222.627204   \n",
              "\n",
              "       mean_G      mean_B                               mean_color_non-white  \\\n",
              "0  231.545656  238.220884  (142.03779977929406, 166.04344176937784, 189.8...   \n",
              "1  141.291904  160.743120  (93.70194947679484, 98.33163709739665, 125.091...   \n",
              "3  179.908240  189.180752  (134.00024836957394, 104.7708350024837, 123.38...   \n",
              "4  242.880320  242.553720  (183.09926209212816, 180.7431296119242, 178.76...   \n",
              "5  222.141480  222.823244  (165.43741130033706, 164.00131940748625, 165.8...   \n",
              "\n",
              "    mean_R_nw   mean_G_nw   mean_B_nw  \\\n",
              "0  142.037800  166.043442  189.859354   \n",
              "1   93.701949   98.331637  125.091200   \n",
              "3  134.000248  104.770835  123.388186   \n",
              "4  183.099262  180.743130  178.767351   \n",
              "5  165.437411  164.001319  165.840884   \n",
              "\n",
              "                                                text language  \\\n",
              "0  Folkmanis Puppets - 2732 - Marionnette Et Théâ...       en   \n",
              "1  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...       en   \n",
              "3  Robot de piscine électrique <p>Ce robot de pis...       fr   \n",
              "4  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...       fr   \n",
              "5  Cadre Universal Pro Mont Accessoires Pour Dji ...       fr   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  folkmanis puppets    marionnette et thtre  min...   \n",
              "1  porte flamme gaxix  flamebringer gaxix    u  t...   \n",
              "3  robot de piscine lectrique pce robot de piscin...   \n",
              "4     hsm destructeur securio c coupe croise  x  mm    \n",
              "5  cadre universal pro mont accessoires pour dji ...   \n",
              "\n",
              "                                      tokenized_text  \\\n",
              "0  [folkmanis, puppets, marionnette, thtre, mini,...   \n",
              "1  [porte, flamme, gaxix, flamebringer, gaxix, u,...   \n",
              "3  [robot, piscine, lectrique, pce, robot, piscin...   \n",
              "4         [hsm, destructeur, securio, coupe, croise]   \n",
              "5  [cadre, universal, pro, mont, accessoires, dji...   \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  [folkmanis, puppet, marionnette, thtre, mini, ...   \n",
              "1  [porte, flamme, gaxix, flamebringer, gaxix, u,...   \n",
              "3  [robot, piscin, lectriqu, pce, robot, piscin, ...   \n",
              "4           [hsm, destructeur, securio, coup, crois]   \n",
              "5  [cadr, universal, pro, mont, accessoir, dji, o...   \n",
              "\n",
              "                                 lemmatized_text_str  \n",
              "0     folkmanis puppet marionnette thtre mini turtle  \n",
              "1  porte flamme gaxix flamebringer gaxix u twilig...  \n",
              "3  robot piscin lectriqu pce robot piscin dun des...  \n",
              "4                 hsm destructeur securio coup crois  \n",
              "5  cadr universal pro mont accessoir dji osmo mob...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0788b9",
      "metadata": {
        "id": "9e0788b9"
      },
      "outputs": [],
      "source": [
        "# As I will only work with the lemmatized text, I will drop unnecessary columns from the data frame\n",
        "df_train_class = df_train[['prdtypecode', 'lemmatized_text_str']]\n",
        "df_test_class = df_test['lemmatized_text_str']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f616e3ea",
      "metadata": {
        "id": "f616e3ea"
      },
      "outputs": [],
      "source": [
        "# I save the data frames with the lemmatized text as pickle files\n",
        "df_train.to_pickle('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/df_train_lemmatized.pkl')\n",
        "df_test.to_pickle('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/df_test_lemmatized.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e385264-ec68-4a4b-92d4-ea8b6607355a",
      "metadata": {
        "id": "8e385264-ec68-4a4b-92d4-ea8b6607355a"
      },
      "outputs": [],
      "source": [
        "file_train = ('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/df_train_lemmatized.pkl')\n",
        "df_train = pickle.load(open(file_train, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8f5a5b",
      "metadata": {
        "id": "cc8f5a5b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "623bb7e9-dfbd-4183-b78f-f425171f6c8c",
      "metadata": {
        "id": "623bb7e9-dfbd-4183-b78f-f425171f6c8c"
      },
      "outputs": [],
      "source": [
        "# Training and test set creation - as I don't have the prdtypecode in the df_test data frame, I will create a train and a test set based on\n",
        "# df_train\n",
        "\n",
        "X = df_train['lemmatized_text_str']\n",
        "y = df_train['prdtypecode']\n",
        "\n",
        "# I chose 15% as the test size, because this reflects the ratio between the actual training and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922376ce",
      "metadata": {
        "id": "922376ce"
      },
      "outputs": [],
      "source": [
        "# Before I can start classification, the text must be converted to TF-IDF vectors\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61b7293-6fa5-4668-a1ff-4a6d8172d90d",
      "metadata": {
        "id": "d61b7293-6fa5-4668-a1ff-4a6d8172d90d"
      },
      "outputs": [],
      "source": [
        "# saving the tfidf vectorized data sets to a pickle file\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Save the sparse matrices to pickle files\n",
        "with open('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/X_train_tfidf.pkl', 'wb') as f:\n",
        "    pickle.dump(X_train_tfidf, f)\n",
        "\n",
        "with open('/Users/katharinastock/Documents/Data Science/Rakuten project/pkl files/X_test_tfidf.pkl', 'wb') as f:\n",
        "    pickle.dump(X_test_tfidf, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc0c1ea",
      "metadata": {
        "id": "4bc0c1ea"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81ec0a8",
      "metadata": {
        "id": "d81ec0a8",
        "outputId": "47495751-533c-4ae0-ed2a-22213830b3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7985196660642052\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          10       0.49      0.49      0.49       400\n",
            "          40       0.75      0.64      0.69       318\n",
            "          50       0.74      0.78      0.76       238\n",
            "          60       0.99      0.76      0.86       127\n",
            "        1140       0.73      0.72      0.73       293\n",
            "        1160       0.88      0.88      0.88       404\n",
            "        1180       0.85      0.47      0.61        87\n",
            "        1280       0.67      0.60      0.63       671\n",
            "        1281       0.71      0.49      0.58       336\n",
            "        1300       0.83      0.93      0.87       698\n",
            "        1301       0.99      0.86      0.92       123\n",
            "        1302       0.82      0.78      0.80       363\n",
            "        1320       0.81      0.77      0.79       414\n",
            "        1560       0.81      0.84      0.83       776\n",
            "        1920       0.88      0.92      0.90       614\n",
            "        1940       0.92      0.78      0.84       104\n",
            "        2060       0.78      0.78      0.78       712\n",
            "        2220       0.92      0.78      0.84       128\n",
            "        2280       0.57      0.84      0.68       644\n",
            "        2403       0.72      0.75      0.74       559\n",
            "        2462       0.75      0.69      0.72       169\n",
            "        2522       0.90      0.92      0.91       694\n",
            "        2582       0.83      0.72      0.77       389\n",
            "        2583       0.97      0.98      0.97      1532\n",
            "        2585       0.80      0.75      0.77       335\n",
            "        2705       0.76      0.69      0.72       356\n",
            "        2905       1.00      0.91      0.95       135\n",
            "\n",
            "    accuracy                           0.80     11619\n",
            "   macro avg       0.81      0.76      0.78     11619\n",
            "weighted avg       0.80      0.80      0.80     11619\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# I will start the classification using Logistic Regression\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "clf_lr = LogisticRegression(random_state=22, max_iter=1000) # I set max_iter to 1000 because before I tried it without any specification of\n",
        "                                                            # max_iter and it could not converge\n",
        "\n",
        "# Train the model\n",
        "clf_lr.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf_lr.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d250be",
      "metadata": {
        "id": "23d250be"
      },
      "outputs": [],
      "source": [
        "# The accuracy for Logistic Regression is okay, but not that great yet\n",
        "# Reviewing the f1-score for the different product type codes, it is visible that the Logistic Regression works\n",
        "# better for some product types than for others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a2ece2",
      "metadata": {
        "id": "33a2ece2",
        "outputId": "95a2357b-395f-4428-e821-b4084a129283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Best Parameters: {'clf__C': 1, 'clf__max_iter': 3000, 'clf__penalty': 'l2', 'clf__solver': 'saga'}\n",
            "Accuracy: 0.798003270505207\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          10       0.49      0.49      0.49       400\n",
            "          40       0.75      0.63      0.69       318\n",
            "          50       0.73      0.78      0.76       238\n",
            "          60       0.99      0.76      0.86       127\n",
            "        1140       0.73      0.72      0.73       293\n",
            "        1160       0.88      0.88      0.88       404\n",
            "        1180       0.85      0.47      0.61        87\n",
            "        1280       0.67      0.60      0.63       671\n",
            "        1281       0.71      0.50      0.59       336\n",
            "        1300       0.82      0.93      0.87       698\n",
            "        1301       0.98      0.87      0.92       123\n",
            "        1302       0.82      0.78      0.80       363\n",
            "        1320       0.80      0.76      0.78       414\n",
            "        1560       0.81      0.84      0.83       776\n",
            "        1920       0.88      0.92      0.90       614\n",
            "        1940       0.92      0.78      0.84       104\n",
            "        2060       0.77      0.78      0.78       712\n",
            "        2220       0.92      0.78      0.84       128\n",
            "        2280       0.57      0.84      0.68       644\n",
            "        2403       0.73      0.75      0.74       559\n",
            "        2462       0.75      0.69      0.72       169\n",
            "        2522       0.90      0.92      0.91       694\n",
            "        2582       0.83      0.72      0.77       389\n",
            "        2583       0.97      0.98      0.97      1532\n",
            "        2585       0.80      0.75      0.77       335\n",
            "        2705       0.76      0.69      0.72       356\n",
            "        2905       1.00      0.91      0.95       135\n",
            "\n",
            "    accuracy                           0.80     11619\n",
            "   macro avg       0.81      0.76      0.78     11619\n",
            "weighted avg       0.80      0.80      0.80     11619\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# I try GridSearchCV for hyperparameter tuning to achieve better results. As it takes too long with the large data set, I tried to implement\n",
        "# some optimization measures such as reducing the number of variations for 'C', choosing 'saga' as the solver and reducing to cv=3 instead\n",
        "# of cv=5\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Set up the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'clf__C': [0.1, 1],\n",
        "    'clf__penalty': ['l1', 'l2'],\n",
        "    'clf__solver': ['saga'],  # 'saga' is supposed to be a good choice for large data sets\n",
        "    'clf__max_iter': [3000, 5000, 10000]\n",
        "}\n",
        "\n",
        "# Create a pipeline with TF-IDF vectorization and logistic regression - it ensures that the same transformations are applied to the training\n",
        "# and the testing data\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LogisticRegression(random_state=22))\n",
        "])\n",
        "\n",
        "# Initialize GridSearchCV with cv=3 for faster computation\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=3,  # Reduced cross-validation folds for faster computation\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the model with grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42bf69e6",
      "metadata": {
        "id": "42bf69e6",
        "outputId": "f4869085-03d4-4e82-ac31-9a3c763d91ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 56\u001b[0m\n\u001b[1;32m     38\u001b[0m param_dist_fine \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__C\u001b[39m\u001b[38;5;124m'\u001b[39m: stats\u001b[38;5;241m.\u001b[39mloguniform(best_params_coarse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__C\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, best_params_coarse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__C\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__penalty\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__l1_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: stats\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, best_params_coarse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__l1_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.1\u001b[39m), \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m, best_params_coarse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__l1_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m)),\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__max_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: [best_params_coarse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__max_iter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2000\u001b[39m, best_params_coarse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__max_iter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m]\n\u001b[1;32m     43\u001b[0m }\n\u001b[1;32m     45\u001b[0m randomized_search_fine \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     46\u001b[0m     pipeline, \n\u001b[1;32m     47\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist_fine, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m randomized_search_fine\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Get the best estimator\u001b[39;00m\n\u001b[1;32m     59\u001b[0m best_clf_fine \u001b[38;5;241m=\u001b[39m randomized_search_fine\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1915\u001b[0m         ParameterSampler(\n\u001b[1;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1917\u001b[0m         )\n\u001b[1;32m   1918\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/Rakuten_project/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# As the results were not really better, I try to adjust more parameters. However, as the computation time was already very long, I will try\n",
        "# a different approach and use RandomizedSearch instead of GridSearchCV. Randomized Search is also supposed to be good at finding the best fit,\n",
        "# but with a better computation time. To speed to process up, I will start with a coarse search and then refine around the most promising ones.\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Pipeline with TF-IDF vectorization and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LogisticRegression(random_state=22, solver='saga'))\n",
        "])\n",
        "\n",
        "# Coarse Search\n",
        "param_dist_coarse = {\n",
        "    'clf__C': stats.loguniform(1e-4, 1e2),  # Equivalent to regularization strength\n",
        "    'clf__penalty': ['elasticnet'],\n",
        "    'clf__l1_ratio': stats.uniform(0, 1),  # Elastic-net mixing parameter\n",
        "    'clf__max_iter': [3000, 5000, 10000]  # Different maximum iterations\n",
        "}\n",
        "\n",
        "randomized_search_coarse = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist_coarse,\n",
        "    n_iter=20,  # Fewer iterations for the coarse search\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=22\n",
        ")\n",
        "\n",
        "randomized_search_coarse.fit(X_train, y_train)\n",
        "\n",
        "best_params_coarse = randomized_search_coarse.best_params_\n",
        "\n",
        "# Fine Search\n",
        "param_dist_fine = {\n",
        "    'clf__C': stats.loguniform(best_params_coarse['clf__C'] / 2, best_params_coarse['clf__C'] * 2),\n",
        "    'clf__penalty': ['elasticnet'],\n",
        "    'clf__l1_ratio': stats.uniform(max(0, best_params_coarse['clf__l1_ratio'] - 0.1), min(1, best_params_coarse['clf__l1_ratio'] + 0.1)),\n",
        "    'clf__max_iter': [best_params_coarse['clf__max_iter'] - 2000, best_params_coarse['clf__max_iter'] + 2000]\n",
        "}\n",
        "\n",
        "randomized_search_fine = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist_fine,\n",
        "    n_iter=20,  # Focused iterations for the fine search\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=22\n",
        ")\n",
        "\n",
        "randomized_search_fine.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_clf_fine = randomized_search_fine.best_estimator_\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_fine = best_clf_fine.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_fine = accuracy_score(y_test, y_pred_fine)\n",
        "report_fine = classification_report(y_test, y_pred_fine)\n",
        "\n",
        "print(f\"Best Parameters: {randomized_search_fine.best_params_}\")\n",
        "print(f\"Accuracy: {accuracy_fine}\")\n",
        "print(\"Classification Report:\\n\", report_fine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae07d9d6-bc2e-4379-96aa-86e56c58ecad",
      "metadata": {
        "id": "ae07d9d6-bc2e-4379-96aa-86e56c58ecad"
      },
      "outputs": [],
      "source": [
        "# re-check how balanced the prdtypecode groups are and if boosting or bagging might be necessary"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}